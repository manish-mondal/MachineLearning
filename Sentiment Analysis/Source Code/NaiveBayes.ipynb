{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTkyrTZSlHXI",
        "outputId": "d4a13db8-65f2-41a3-f9b1-33c7bda87a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "(10000, 17613)\n",
            "   usual                                            review_  polarity  \\\n",
            "0    0.0  I usually love going to this t-mobile. The rep...  0.207273   \n",
            "1    0.0  The store gave me misleading information.  One...  0.019444   \n",
            "2    0.0  Nice, stand-alone T-Mobile in the parking lot ...  0.433333   \n",
            "3    0.0  I get awesome service every time I come here. ...  0.221875   \n",
            "4    0.0  Very busy I waited for 45 min before even bein...  0.300000   \n",
            "\n",
            "          sentiment_  love   go  tmobil  repres  alway  nice  ...  200mbps  \\\n",
            "0  Slightly Positive   0.0  0.0     0.0     0.0    0.0   0.0  ...      0.0   \n",
            "1  Slightly Negative   0.0  0.0     0.0     0.0    0.0   0.0  ...      0.0   \n",
            "2           Positive   0.0  0.0     0.0     0.0    0.0   0.0  ...      0.0   \n",
            "3  Slightly Positive   0.0  0.0     0.0     0.0    0.0   0.0  ...      0.0   \n",
            "4  Slightly Positive   0.0  0.0     0.0     0.0    0.0   0.0  ...      0.0   \n",
            "\n",
            "   50mbps  starlink  sparklightcar  10100  17044  dvrs  22649   cn  \\\n",
            "0     0.0       0.0            0.0    0.0    0.0   0.0    0.0  0.0   \n",
            "1     0.0       0.0            0.0    0.0    0.0   0.0    0.0  0.0   \n",
            "2     0.0       0.0            0.0    0.0    0.0   0.0    0.0  0.0   \n",
            "3     0.0       0.0            0.0    0.0    0.0   0.0    0.0  0.0   \n",
            "4     0.0       0.0            0.0    0.0    0.0   0.0    0.0  0.0   \n",
            "\n",
            "   screendigit  \n",
            "0          0.0  \n",
            "1          0.0  \n",
            "2          0.0  \n",
            "3          0.0  \n",
            "4          0.0  \n",
            "\n",
            "[5 rows x 17613 columns]\n",
            "['Slightly Positive' 'Slightly Negative' 'Positive' 'Negative']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount(\"/content/drive\",force_remount=True)\n",
        "INPUT_FILEBASE = \"/content/drive/MyDrive/yelp_dataset_in/\"\n",
        "OUTPUT_FILEBASE = \"/content/drive/MyDrive/yelp_dataset_out/\"\n",
        "\n",
        "pickle_name = \"yelp_reviews_Electronics_categories_final.pickle\"\n",
        "df1 = pd.read_pickle(\"%s%s\" %(OUTPUT_FILEBASE,pickle_name))\n",
        "print(df1.shape)\n",
        "print(df1.head())\n",
        "print(df1[\"sentiment_\"].unique())\n",
        "\n",
        "X = df1.review_\n",
        "y = df1.sentiment_\n",
        "indices = df1.index\n",
        "\n",
        "X_train, X_test, y_train, y_test, i_train, i_test = train_test_split(X, y, indices, train_size = 0.8, random_state = 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes with CountVectorizer**"
      ],
      "metadata": {
        "id": "u_ePvfJvm7JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "steps = [('vec', CountVectorizer(stop_words = 'english', ngram_range = (1, 2))), ('nb', MultinomialNB())] \n",
        "pipeline = Pipeline(steps) \n",
        "parameters = {'vec__min_df':[0.01, 0.1, 1, 10, 100], 'nb__alpha':[0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "clf = GridSearchCV(pipeline, parameters, cv = 5, scoring=\"accuracy\") \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(clf.best_params_)\n",
        "results = clf.predict(X_test)\n",
        "test_accuracy = clf.score(X_test, y_test)\n",
        "probs = clf.predict_proba(X_test)[:, 1]\n",
        "f1_accuracy = f1_score(y_test,results,average='macro')\n",
        "f1_accuracym = f1_score(y_test,results,average='micro')\n",
        "f1_accuracyw = f1_score(y_test,results,average='weighted')\n",
        "print(\"Accuracy on test data: \" ,test_accuracy)\n",
        "print('F1 Score (macro): ', f1_accuracy)\n",
        "print('F1 Score (micro): ', f1_accuracym)\n",
        "print('F1 Score (weighted): ', f1_accuracyw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGvq_l-qlprD",
        "outputId": "18212a30-e909-40f7-f0bf-1cab9b75012e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'nb__alpha': 0.01, 'vec__min_df': 10}\n",
            "Accuracy on test data:  0.6135\n",
            "F1 Score (macro):  0.5980484065627263\n",
            "F1 Score (micro):  0.6135\n",
            "F1 Score (weighted):  0.6117488859877542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes with TFIDF**"
      ],
      "metadata": {
        "id": "TMJ-uMR4m9xz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "steps = [('vec', TfidfVectorizer(stop_words = 'english', ngram_range = (1, 2))), ('nb', MultinomialNB())] \n",
        "pipeline = Pipeline(steps) \n",
        "parameters = {'vec__min_df':[0.01, 0.1, 1, 10, 100], 'nb__alpha':[0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "clf = GridSearchCV(pipeline, parameters, cv = 10, scoring=\"accuracy\") \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(clf.best_params_)\n",
        "results = clf.predict(X_test)\n",
        "test_accuracy = clf.score(X_test, y_test)\n",
        "probs = clf.predict_proba(X_test)[:, 1]\n",
        "f1_accuracy = f1_score(y_test,results,average='macro')\n",
        "f1_accuracym = f1_score(y_test,results,average='micro')\n",
        "f1_accuracyw = f1_score(y_test,results,average='weighted')\n",
        "print(\"Accuracy on test data: \" ,test_accuracy)\n",
        "print('F1 Score (macro): ', f1_accuracy)\n",
        "print('F1 Score (micro): ', f1_accuracym)\n",
        "print('F1 Score (weighted): ', f1_accuracyw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr9tq3qvnBVD",
        "outputId": "f479fbcd-8239-46ee-83cf-a861a7ad9b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'nb__alpha': 0.1, 'vec__min_df': 10}\n",
            "Accuracy on test data:  0.6085\n",
            "F1 Score (macro):  0.5553626505573198\n",
            "F1 Score (micro):  0.6085\n",
            "F1 Score (weighted):  0.5913411714973592\n"
          ]
        }
      ]
    }
  ]
}