{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-m0eTjqSrkR",
        "outputId": "dec3d542-c252-4a1f-dc4c-0ace94257935"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "(10000, 17613)\n",
            "   usual                                            review_  polarity  \\\n",
            "0    0.0  I usually love going to this t-mobile. The rep...  0.207273   \n",
            "1    0.0  The store gave me misleading information.  One...  0.019444   \n",
            "2    0.0  Nice, stand-alone T-Mobile in the parking lot ...  0.433333   \n",
            "3    0.0  I get awesome service every time I come here. ...  0.221875   \n",
            "4    0.0  Very busy I waited for 45 min before even bein...  0.300000   \n",
            "\n",
            "          sentiment_  love   go  tmobil  repres  alway  nice  ...  200mbps  \\\n",
            "0  Slightly Positive   0.0  0.0     0.0     0.0    0.0   0.0  ...      0.0   \n",
            "1  Slightly Negative   0.0  0.0     0.0     0.0    0.0   0.0  ...      0.0   \n",
            "2           Positive   0.0  0.0     0.0     0.0    0.0   0.0  ...      0.0   \n",
            "3  Slightly Positive   0.0  0.0     0.0     0.0    0.0   0.0  ...      0.0   \n",
            "4  Slightly Positive   0.0  0.0     0.0     0.0    0.0   0.0  ...      0.0   \n",
            "\n",
            "   50mbps  starlink  sparklightcar  10100  17044  dvrs  22649   cn  \\\n",
            "0     0.0       0.0            0.0    0.0    0.0   0.0    0.0  0.0   \n",
            "1     0.0       0.0            0.0    0.0    0.0   0.0    0.0  0.0   \n",
            "2     0.0       0.0            0.0    0.0    0.0   0.0    0.0  0.0   \n",
            "3     0.0       0.0            0.0    0.0    0.0   0.0    0.0  0.0   \n",
            "4     0.0       0.0            0.0    0.0    0.0   0.0    0.0  0.0   \n",
            "\n",
            "   screendigit  \n",
            "0          0.0  \n",
            "1          0.0  \n",
            "2          0.0  \n",
            "3          0.0  \n",
            "4          0.0  \n",
            "\n",
            "[5 rows x 17613 columns]\n",
            "['Slightly Positive' 'Slightly Negative' 'Positive' 'Negative']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix,make_scorer, accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "drive.mount(\"/content/drive\",force_remount=True)\n",
        "INPUT_FILEBASE = \"/content/drive/MyDrive/yelp_dataset_in/\"\n",
        "OUTPUT_FILEBASE = \"/content/drive/MyDrive/yelp_dataset_out/\"\n",
        "\n",
        "pickle_name = \"yelp_reviews_Electronics_categories_final.pickle\"\n",
        "df1 = pd.read_pickle(\"%s%s\" %(OUTPUT_FILEBASE,pickle_name))\n",
        "print(df1.shape)\n",
        "print(df1.head())\n",
        "print(df1[\"sentiment_\"].unique())\n",
        "\n",
        "X = df1.iloc[0:,4:]\n",
        "y = df1.sentiment_\n",
        "indices = df1.index\n",
        "X_train, X_test, y_train, y_test, itrain, itest = train_test_split(X,y,indices,train_size=0.8,random_state=7)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps = [('scaler', StandardScaler()), ('lr', LogisticRegression(solver = 'lbfgs',max_iter=1000))] \n",
        "pipeline = Pipeline(steps)\n",
        "parameters = {'lr__C':[0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "\n",
        "clf = GridSearchCV(pipeline, parameters, cv = 5, scoring=\"accuracy\") \n",
        "clf.fit(X_train, y_train)\n",
        "print(clf.best_params_)\n",
        "results = clf.predict(X_test)\n",
        "test_accuracy = clf.score(X_test, y_test)\n",
        "f1_accuracy = f1_score(y_test,results,average='macro')\n",
        "f1_accuracym = f1_score(y_test,results,average='micro')\n",
        "f1_accuracyw = f1_score(y_test,results,average='weighted')\n",
        "print(\"Accuracy on test data: \" ,test_accuracy)\n",
        "print('F1 Score (macro): ', f1_accuracy)\n",
        "print('F1 Score (micro): ', f1_accuracym)\n",
        "print('F1 Score (weighted): ', f1_accuracyw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80NOIHGnVsbL",
        "outputId": "8167fd91-d551-4719-dfd4-d150e0934e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'lr__C': 0.01}\n",
            "Accuracy on test data:  0.597\n",
            "F1 Score (macro):  0.5910366394608606\n",
            "F1 Score (micro):  0.597\n",
            "F1 Score (weighted):  0.5964990122086132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "steps = [('scaler', StandardScaler()), ('rf', RandomForestClassifier())] \n",
        "pipeline = Pipeline(steps) \n",
        "parameters = {'rf__n_estimators':[10 , 20, 30, 40, 50], 'rf__max_features':['auto','sqrt']}\n",
        "clf = GridSearchCV(pipeline, parameters, cv = 5, scoring=\"accuracy\") \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(clf.best_params_)\n",
        "results = clf.predict(X_test)\n",
        "test_accuracy = clf.score(X_test, y_test)\n",
        "f1_accuracy = f1_score(y_test,results,average='macro')\n",
        "f1_accuracym = f1_score(y_test,results,average='micro')\n",
        "f1_accuracyw = f1_score(y_test,results,average='weighted')\n",
        "print(\"Accuracy on test data: \" ,test_accuracy)\n",
        "print('F1 Score (macro): ', f1_accuracy)\n",
        "print('F1 Score (micro): ', f1_accuracym)\n",
        "print('F1 Score (weighted): ', f1_accuracyw)"
      ],
      "metadata": {
        "id": "G-eTqXqvacCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9431a9be-3249-4408-ecc7-10e0407302a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test data:  0.6225\n",
            "F1 Score (macro):  0.5939848272105531\n",
            "F1 Score (micro):  0.6225\n",
            "F1 Score (weighted):  0.6140657913939286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "steps = [('scaler', StandardScaler()), ('svc', SVC(probability=False,kernel='linear',gamma='auto'))] \n",
        "pipeline = Pipeline(steps) \n",
        "parameters = {'svc__C':[0.01, 0.1, 1]}\n",
        "\n",
        "clf = GridSearchCV(pipeline, parameters, cv = 3, scoring=\"accuracy\") \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(clf.best_params_)\n",
        "results = clf.predict(X_test)\n",
        "test_accuracy = clf.score(X_test, y_test)\n",
        "f1_accuracy = f1_score(y_test,results,average='macro')\n",
        "f1_accuracym = f1_score(y_test,results,average='micro')\n",
        "f1_accuracyw = f1_score(y_test,results,average='weighted')\n",
        "print(\"Accuracy on test data: \" ,test_accuracy)\n",
        "print('F1 Score (macro): ', f1_accuracy)\n",
        "print('F1 Score (micro): ', f1_accuracym)\n",
        "print('F1 Score (weighted): ', f1_accuracyw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEdx1r0NfZZo",
        "outputId": "3d9c3e60-35df-46a1-db18-652a11a4c95c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'svc__C': 0.01}\n",
            "Accuracy on test data:  0.619\n",
            "F1 Score (macro):  0.6133826082582902\n",
            "F1 Score (micro):  0.619\n",
            "F1 Score (weighted):  0.6193411529481063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a5IEiGnJqycD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svmClassifier = SVC()\n",
        "svmClassifier.fit(X_train, y_train)\n",
        "\n",
        "predictions = svmClassifier.predict(X_test)\n",
        "\n",
        "# clf2 = SVC(solver = 'lbfgs')\n",
        "# model = Pipeline([('classifier',clf2)])\n",
        "# model.fit(Xtrain, ytrain)\n",
        "# predictions = model.predict(Xtest)\n",
        "mat = confusion_matrix(y_test,predictions)\n",
        "cm_df =  pd.DataFrame(mat, index= [i for i in ['Negative','Positive',\n",
        "                                               'Slightly Negative',\n",
        "                                              'Slightly Positive']],\n",
        "                     columns= [i for i in ['Negative','Positive',\n",
        "                                               'Slightly Negative',\n",
        "                                              'Slightly Positive']])\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(cm_df, annot=True,cmap='Blues',fmt='g')\n",
        "\n",
        "\n",
        "print('Accuracy Score: ',accuracy_score(predictions,y_test))\n",
        "# cm = confusion_matrix(list(ytest),list(predictions))\n",
        "# print(cm)\n",
        "\n",
        "#Calculate sihouette Score\n",
        "# score = metrics.silhouette_score(X_test, y_pred)\n",
        "# print(\"Sihouette Score: \",score) \n",
        "\n"
      ],
      "metadata": {
        "id": "WTKI5B9vanoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f5b19a8-9020-48db-ef7e-be676c02a0fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score:  0.7165\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "steps = [('scaler', StandardScaler()), ('gbc', GradientBoostingClassifier(max_features='sqrt'))] \n",
        "pipeline = Pipeline(steps) \n",
        "parameters = {'gbc__n_estimators':[10, 50, 100, 200, 500], 'gbc__learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25]}\n",
        "\n",
        "clf = GridSearchCV(pipeline, parameters, cv = 5, scoring=\"accuracy\") \n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "clf.best_params_\n",
        "steps = [('scaler', StandardScaler()), ('gbc', GradientBoostingClassifier(learning_rate = 0.15, max_features = 'sqrt', n_estimators = 500))] \n",
        "clf = Pipeline(steps) \n",
        "clf.fit(X_train, y_train)\n",
        "results = clf.predict(X_test)\n",
        "test_accuracy = clf.score(X_test, y_test)\n",
        "probs = clf.predict_proba(X_test)[:, 1]\n",
        "f1_accuracy = f1_score(y_test,results,average='macro')\n",
        "f1_accuracym = f1_score(y_test,results,average='micro')\n",
        "f1_accuracyw = f1_score(y_test,results,average='weighted')\n",
        "print(\"Accuracy on test data: \" ,test_accuracy)\n",
        "print('F1 Score (macro): ', f1_accuracy)\n",
        "print('F1 Score (micro): ', f1_accuracym)\n",
        "print('F1 Score (weighted): ', f1_accuracyw)"
      ],
      "metadata": {
        "id": "rOZ7065davKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I8tBVjkQVrdL"
      }
    }
  ]
}